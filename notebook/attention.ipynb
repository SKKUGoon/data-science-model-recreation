{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbef232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "root_dir = os.path.abspath(\"..\")\n",
    "sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b8414b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0916c6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "from models.attention.self_attention import SelfAttention\n",
    "\n",
    "batch = 3\n",
    "prev_token_len = 4\n",
    "embedding_dim = 4\n",
    "\n",
    "X = torch.rand(batch, prev_token_len, embedding_dim)\n",
    "\n",
    "mask = torch.tensor([\n",
    "    [1, 1, 1, 0],\n",
    "    [1, 1, 0, 0],\n",
    "    [1, 0, 0, 0]\n",
    "])\n",
    "\n",
    "attention_mask = mask.unsqueeze(1).repeat(1, 4, 1)\n",
    "\n",
    "model = SelfAttention(dim=4)\n",
    "output = model(X, attention_mask=attention_mask)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c9c38d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2223, -0.0077, -0.6081, -0.1408],\n",
       "         [-0.2230, -0.0079, -0.6075, -0.1404],\n",
       "         [-0.2221, -0.0076, -0.6083, -0.1409],\n",
       "         [-0.1926,  0.0521, -0.5403, -0.1808]],\n",
       "\n",
       "        [[-0.2673, -0.0152, -0.5257, -0.0983],\n",
       "         [-0.1297,  0.1419, -0.4511, -0.2405],\n",
       "         [-0.2675, -0.0155, -0.5259, -0.0981],\n",
       "         [-0.1315,  0.1397, -0.4516, -0.2381]],\n",
       "\n",
       "        [[-0.0744,  0.2084, -0.4364, -0.3122],\n",
       "         [-0.2826,  0.0484, -0.4286, -0.1472],\n",
       "         [-0.2826,  0.0484, -0.4286, -0.1472],\n",
       "         [-0.2826,  0.0484, -0.4286, -0.1472]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dab172a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 16])\n",
      "tensor([[[-1.8696e-01,  2.7355e-01, -6.5205e-02,  3.3045e-02,  3.2881e-01,\n",
      "          -6.1468e-02, -9.1805e-02, -4.0093e-02,  1.3089e-01, -3.0453e-01,\n",
      "          -1.3783e-01,  1.9197e-01,  5.5382e-02, -1.4518e-01,  1.9904e-01,\n",
      "          -2.5740e-01],\n",
      "         [-2.1637e-01,  4.1156e-01, -6.2698e-02,  4.9926e-02,  1.8843e-01,\n",
      "          -4.2594e-02, -1.3175e-01, -3.7726e-02,  1.4813e-01, -1.8220e-01,\n",
      "          -1.5656e-01,  1.2822e-01,  8.0046e-02, -2.6929e-01,  2.2269e-01,\n",
      "          -2.5567e-01],\n",
      "         [-2.4690e-01,  3.7586e-01, -4.9122e-02,  9.5958e-02,  2.3354e-01,\n",
      "          -6.7629e-02, -8.9723e-02,  3.7922e-02,  4.0753e-02, -1.4260e-01,\n",
      "          -1.3525e-01,  1.7596e-01,  5.3064e-02, -1.8468e-01,  2.7502e-01,\n",
      "          -2.8437e-01],\n",
      "         [-2.0603e-01,  3.1289e-01, -2.7860e-02,  6.4784e-02,  1.5455e-01,\n",
      "          -5.0996e-02, -3.1922e-02, -1.5027e-02,  2.3241e-02, -1.2233e-01,\n",
      "          -8.3906e-02,  1.9684e-01,  5.3164e-02, -1.7261e-01,  2.4217e-01,\n",
      "          -2.2254e-01]],\n",
      "\n",
      "        [[-2.6625e-01,  4.8304e-01,  1.2805e-01,  9.8700e-03, -4.3962e-02,\n",
      "           1.0356e-04, -1.9613e-01,  1.1566e-01,  1.7087e-01, -2.7415e-01,\n",
      "           1.1453e-02,  1.2433e-01,  1.0187e-01, -2.0235e-01,  2.1276e-01,\n",
      "          -1.2963e-01],\n",
      "         [-1.8613e-01,  3.5709e-01, -5.2410e-02,  4.0742e-03,  1.2162e-01,\n",
      "          -6.9622e-02, -5.1080e-02,  1.2638e-01,  8.9971e-02, -2.8949e-01,\n",
      "          -6.8844e-02,  1.6050e-01,  7.7928e-02, -9.4865e-02,  1.3896e-01,\n",
      "          -1.1688e-01],\n",
      "         [-2.1102e-01,  3.2847e-01, -1.1874e-01, -7.6070e-03,  1.8931e-01,\n",
      "          -7.3938e-02, -5.2353e-02,  2.8405e-02,  4.2668e-02, -2.4527e-01,\n",
      "          -1.5972e-01,  2.1999e-01,  6.9450e-02, -1.0343e-01,  2.1590e-01,\n",
      "          -2.2301e-01],\n",
      "         [-2.0501e-01,  1.6920e-01, -8.6430e-02, -2.0355e-02,  2.3352e-01,\n",
      "          -7.9765e-02, -3.2578e-02,  7.3308e-03,  4.2886e-02, -3.1369e-01,\n",
      "          -1.1498e-01,  2.1839e-01,  6.3751e-02, -3.5239e-02,  1.9120e-01,\n",
      "          -1.7214e-01]],\n",
      "\n",
      "        [[-8.1932e-02,  3.0059e-02, -6.3149e-02,  9.1710e-03,  6.6179e-02,\n",
      "          -8.1572e-02, -9.1111e-02, -2.5143e-02, -2.8192e-02,  8.3759e-02,\n",
      "          -7.8633e-02, -8.6159e-02, -6.5332e-02, -1.1010e-01,  1.8734e-01,\n",
      "          -1.3807e-01],\n",
      "         [-2.4827e-01,  2.7483e-01, -7.5827e-02, -3.3087e-02,  1.4047e-01,\n",
      "          -7.9168e-02, -6.5108e-02,  2.4349e-02,  1.2794e-01, -2.1552e-01,\n",
      "          -2.1748e-01,  1.1045e-01,  1.1566e-01, -1.7864e-01,  1.5768e-01,\n",
      "          -7.4491e-02],\n",
      "         [-2.1178e-01,  2.2222e-01, -5.0976e-02,  8.0817e-03,  1.5694e-01,\n",
      "          -1.6608e-01,  4.4752e-02, -6.2105e-02,  1.2670e-01, -1.7814e-01,\n",
      "          -2.1005e-01,  1.4467e-01,  1.5727e-01, -1.4787e-01,  1.0703e-01,\n",
      "          -3.9467e-02],\n",
      "         [-3.0493e-01,  2.1556e-01, -1.0173e-01,  8.9367e-03,  2.6215e-01,\n",
      "          -1.6280e-01,  2.0595e-02, -1.5976e-03,  1.3834e-01, -2.3916e-01,\n",
      "          -2.0571e-01,  1.2830e-01,  1.2954e-01, -1.6657e-01,  1.6960e-01,\n",
      "          -1.3944e-01]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from models.attention.multi_head_self_attention import MultiHeadSelfAttention\n",
    "\n",
    "batch = 3\n",
    "prev_token_len = 4\n",
    "number_of_heads = 4\n",
    "embedding_dim = 16\n",
    "\n",
    "# input tensor\n",
    "X = torch.rand(batch, prev_token_len, embedding_dim)\n",
    "\n",
    "# Attention mask (batch, 1, prev_token_len, prev_token_len)\n",
    "attention_mask = torch.tril(torch.ones(prev_token_len, prev_token_len))\n",
    "attention_mask = attention_mask.unsqueeze(0).unsqueeze(0).repeat(batch, 1, 1, 1)\n",
    "\n",
    "# Instantiate the multi-head attention\n",
    "net = MultiHeadSelfAttention(\n",
    "    dim=embedding_dim, \n",
    "    n_heads=number_of_heads, \n",
    "    per_head_dim=16\n",
    ")\n",
    "\n",
    "output = net(X, attention_mask=attention_mask)\n",
    "print(output.shape)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05afb1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e3ac1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
